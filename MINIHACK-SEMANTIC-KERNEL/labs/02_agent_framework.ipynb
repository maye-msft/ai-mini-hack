{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62df6f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from openai import AsyncAzureOpenAI\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "\n",
    "from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread, AzureAIAgent, AzureAIAgentThread, SequentialOrchestration\n",
    "from semantic_kernel.agents.runtime import InProcessRuntime\n",
    "from semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion import AzureChatCompletion\n",
    "from semantic_kernel.contents import AuthorRole, ChatMessageContent\n",
    "from semantic_kernel.core_plugins import ConversationSummaryPlugin, MathPlugin\n",
    "\n",
    "# Setup\n",
    "load_dotenv(override=True)\n",
    "azure_chat_completion = AzureChatCompletion(\n",
    "    service_id=\"azure_openai_chat\",\n",
    "    async_client=AsyncAzureOpenAI(\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        api_version=os.getenv(\"MODEL_DEPLOYMENT_API_VERSION\"),\n",
    "    ),\n",
    "    deployment_name=os.getenv(\"MODEL_DEPLOYMENT_NAME\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089df204",
   "metadata": {},
   "source": [
    "# Part 1: Create a single agent, a thread and run the agent\n",
    "\n",
    "## ChatCompletionAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d9efdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You: hi\n",
      "Bot: Hello! How can I assist you with your math questions today?\n",
      "\n",
      "You: how are ypu?\n",
      "Bot: I'm just a computer program, so I don't have feelings, but I'm here and ready to help you! How can I assist you today?\n",
      "\n",
      "You: what is 1+1\n",
      "Bot: The sum of 1 + 1 is 2.0.\n",
      "\n",
      "You: \n",
      "Bot: Do you have any more math questions or anything else you'd like to know?\n",
      "\n",
      "You: quit\n"
     ]
    }
   ],
   "source": [
    "# 1. Create the agent\n",
    "teacher_agent = ChatCompletionAgent(\n",
    "    service=azure_chat_completion,\n",
    "    name=\"TeacherAssistant\",\n",
    "    instructions=\"Answer the math questions of the student.\",\n",
    "    plugins=[MathPlugin()],\n",
    ")\n",
    "\n",
    "# 2. Create the thread\n",
    "thread: ChatHistoryAgentThread = ChatHistoryAgentThread()\n",
    "\n",
    "# 3. Run the agent as a chat\n",
    "while True:\n",
    "    user_input = input(\"Enter your message:\")\n",
    "    print(f\"\\nYou: {user_input}\")\n",
    "\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        break\n",
    "\n",
    "    response = await teacher_agent.get_response(\n",
    "        messages=user_input,\n",
    "        thread=thread, \n",
    "    )\n",
    "\n",
    "    assistant_reply = str(response)\n",
    "    print(f\"Bot: {assistant_reply}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ced0c4",
   "metadata": {},
   "source": [
    "### ðŸ§ª Try it out!\n",
    "\n",
    "Now that youâ€™ve created a `ChatCompletionAgent`, try chatting with it! ðŸ’¬\n",
    "\n",
    "Youâ€™ll notice itâ€™s much simpler than using the kernel directly â€” the agent takes care of prompts, memory, and tool orchestration for you. ðŸ§ âš™ï¸\n",
    "\n",
    "> ðŸ’¡ **Did you know?** If you assign a kernel to the agent, it can automatically use everything configured in that kernel â€” including plugins, services, filters, and memory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e2e4b5",
   "metadata": {},
   "source": [
    "## AzureAIAgentâ€‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0957bae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You: Hello\n",
      "Bot: Hi there! How can I assist you today?\n",
      "\n",
      "You: What are you doing?\n",
      "Bot: I'm here to assist you with any questions or tasks you might have. How can I help you?\n",
      "\n",
      "You: Can you summarize everything?\n",
      "Bot: Sure! Could you please provide the text or content you would like summarized?\n",
      "\n",
      "You: this conversation\n",
      "Bot: It seems there was an error in processing the request. Let me summarize the conversation for you:\n",
      "\n",
      "1. You greeted by saying \"Hello.\"\n",
      "2. I responded, offering assistance.\n",
      "3. You asked what I was doing.\n",
      "4. I explained my purpose is to assist with questions or tasks.\n",
      "5. You requested a summary of our conversation.\n",
      "6. I asked for the specific content you'd like summarized.\n",
      "\n",
      "You: exit\n"
     ]
    }
   ],
   "source": [
    "async with (\n",
    "    DefaultAzureCredential() as creds,\n",
    "    AzureAIAgent.create_client(credential=creds, endpoint=os.getenv(\"AIPROJECT_ENDPOINT\")) as client,\n",
    "):\n",
    "    # 1. Define an agent on the Azure AI agent service \n",
    "    agent_definition = await client.agents.create_agent(\n",
    "        model=os.getenv(\"MODEL_DEPLOYMENT_NAME\"),\n",
    "        name=\"SecretaryAssistant\",\n",
    "        instructions=\"You are a summarization assistant. Help users understand long content by summarizing it.\",\n",
    "    )\n",
    "\n",
    "    # 2. Create an agent instance with the definition and plugins\n",
    "    secretary_agent = AzureAIAgent(\n",
    "        client=client,\n",
    "        definition=agent_definition,\n",
    "        plugins=[ConversationSummaryPlugin]\n",
    "    )\n",
    "\n",
    "    # 3. Create a thread on the Azure AI agent service \n",
    "    thread: AzureAIAgentThread = AzureAIAgentThread(client=client)\n",
    "\n",
    "    # 4. Run the agent as a chat\n",
    "    while True:\n",
    "        user_input = input(\"Enter your message:\")\n",
    "        print(f\"\\nYou: {user_input}\")\n",
    "\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            break\n",
    "\n",
    "        response = await secretary_agent.get_response(\n",
    "            messages=[user_input], thread=thread\n",
    "        )\n",
    "\n",
    "        assistant_reply = str(response)\n",
    "        print(f\"Bot: {assistant_reply}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db77c227",
   "metadata": {},
   "source": [
    "### ðŸ§ª Try it out!\n",
    "\n",
    "Now try interacting with your `AzureAIAgent`! ðŸ’¬\n",
    "\n",
    "ðŸ’¡ **Did you know?** When you create the agent and thread, Semantic Kernel registers them in your Azure AI Foundry project. The Azure AI Agent Service automatically persists both the agent definition and conversation threadâ€”no manual storage required.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§© Challenge\n",
    "\n",
    "1. Enhance your `AzureAIAgent` by adding advanced built-in tools such as:\n",
    "   - BingGrounding\n",
    "   - File Search\n",
    "   - Code Interpreter\n",
    "   - OpenAPI-based integrations  \n",
    "   (all supported by Azure AI Agent Service)\n",
    "\n",
    "2. Explore other **agent types** available in Semantic Kernelâ€™s Python SDK, including:\n",
    "   - `ChatCompletionAgent`\n",
    "   - `OpenAIAssistantAgent`\n",
    "   - `AzureAIAgent`\n",
    "   - `OpenAIResponsesAgent`  \n",
    "   These agents vary by their underlying LLM connector and orchestration capabilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f4694a",
   "metadata": {},
   "source": [
    "# Part 2: Multi-agent orchestration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468a3f23",
   "metadata": {},
   "source": [
    "- Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbdcd958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_response_callback(message: ChatMessageContent) -> None:\n",
    "    print(f\"# {message.name}\\n\\n{message.content}\\n\")\n",
    "    \n",
    "def human_response_function() -> ChatMessageContent:\n",
    "    user_input = input(\"User: \")\n",
    "    return ChatMessageContent(role=AuthorRole.USER, content=user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2b56d3",
   "metadata": {},
   "source": [
    "- Define the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f1faab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_agents = [\n",
    "    ChatCompletionAgent(\n",
    "        service=azure_chat_completion,\n",
    "        name=\"ConceptExtractorAgent\",\n",
    "        instructions=(\n",
    "            \"You are a marketing analyst. Given a product description, identify:\\n\"\n",
    "            \"- Key features\\n\"\n",
    "            \"- Target audience\\n\"\n",
    "            \"- Unique selling points\\n\\n\"\n",
    "        ),\n",
    "    ),\n",
    "    ChatCompletionAgent(\n",
    "        service=azure_chat_completion,\n",
    "        name=\"WriterAgent\",\n",
    "        instructions=(\n",
    "            \"You are a marketing copywriter. Given a block of text describing features, audience, and USPs, \"\n",
    "            \"compose a compelling marketing copy (like a newsletter section) that highlights these points. \"\n",
    "            \"Output should be short (around 150 words), output just the copy as a single text block.\"\n",
    "        ),        \n",
    "    ),\n",
    "    ChatCompletionAgent(\n",
    "        service=azure_chat_completion,\n",
    "        name=\"FormatProofAgent\",\n",
    "        instructions=(\n",
    "            \"You are an editor. Given the draft copy, correct grammar, improve clarity, ensure consistent tone, \"\n",
    "            \"give format and make it polished. Output the final improved copy as a single text block.\"\n",
    "        )\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55584140",
   "metadata": {},
   "source": [
    "- Run the orchestration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee920504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ConceptExtractorAgent\n",
      "\n",
      "Key Features:\n",
      "- Made from stainless steel\n",
      "- Eco-friendly materials\n",
      "- Insulation that maintains cold temperatures for up to 24 hours\n",
      "\n",
      "Target Audience:\n",
      "- Environmentally conscious consumers \n",
      "- Individuals looking for durable, high-quality drinkware\n",
      "- Outdoor enthusiasts, athletes, and travelers seeking temperature retention in water bottles\n",
      "\n",
      "Unique Selling Points:\n",
      "- Long-lasting temperature retention (24 hours for cold drinks)\n",
      "- Sustainable, eco-friendly materials\n",
      "- Durable stainless steel construction\n",
      "\n",
      "# WriterAgent\n",
      "\n",
      "Stay refreshed and sustainable with our state-of-the-art EcoFlow Flask, crafted for those who demand durability and temperature retention without compromising on eco-friendliness. Made from premium stainless steel, our flask is designed to cater to the needs of outdoor enthusiasts, athletes, and travelers who seek adventure with every sip. Trust in our advanced insulation technology to keep your drinks crisp and cold for up to 24 hours, ensuring your hydration is as fresh as your impact on the planet. Join the movement towards conscious consumption with a flask that reflects your lifestyleâ€”high-quality, eco-friendly, and built to endure. Whether tackling rugged trails or bustling city streets, EcoFlow Flask is your sustainable companion for every journey. Choose durability, choose earth-firstâ€”choose EcoFlow.\n",
      "\n",
      "# FormatProofAgent\n",
      "\n",
      "Stay refreshed and sustainable with our state-of-the-art EcoFlow Flask, crafted for those who demand durability and temperature retention without compromising on eco-friendliness. Made from premium stainless steel, our flask is designed to cater to the needs of outdoor enthusiasts, athletes, and travelers who seek adventure with every sip. Trust in our advanced insulation technology to keep your drinks crisp and cold for up to 24 hours, ensuring your hydration is as fresh as your impact on the planet. Join the movement towards conscious consumption with a flask that reflects your lifestyleâ€”high-quality, eco-friendly, and built to endure. Whether tackling rugged trails or bustling city streets, EcoFlow Flask is your sustainable companion for every journey. Choose durability, choose earth-firstâ€”choose EcoFlow.\n",
      "\n",
      "***** Final Result *****\n",
      "Stay refreshed and sustainable with our state-of-the-art EcoFlow Flask, crafted for those who demand durability and temperature retention without compromising on eco-friendliness. Made from premium stainless steel, our flask is designed to cater to the needs of outdoor enthusiasts, athletes, and travelers who seek adventure with every sip. Trust in our advanced insulation technology to keep your drinks crisp and cold for up to 24 hours, ensuring your hydration is as fresh as your impact on the planet. Join the movement towards conscious consumption with a flask that reflects your lifestyleâ€”high-quality, eco-friendly, and built to endure. Whether tackling rugged trails or bustling city streets, EcoFlow Flask is your sustainable companion for every journey. Choose durability, choose earth-firstâ€”choose EcoFlow.\n"
     ]
    }
   ],
   "source": [
    "# 1. Create the orchestration\n",
    "sequential_orchestration = SequentialOrchestration(\n",
    "    members=sequential_agents,\n",
    "    agent_response_callback=agent_response_callback,\n",
    ")\n",
    "\n",
    "# 2. Create and run the orchestration runtime\n",
    "runtime = InProcessRuntime()\n",
    "runtime.start()\n",
    "\n",
    "# 3. Invoke the orchestration with a task\n",
    "orchestration_result = await sequential_orchestration.invoke(\n",
    "    task=\"An eco-friendly stainless steel water bottle that keeps drinks cold for 24 hours\",\n",
    "    runtime=runtime,\n",
    ")\n",
    "\n",
    "# 4. Get the final result\n",
    "value = await orchestration_result.get(timeout=50)\n",
    "print(f\"***** Final Result *****\\n{value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca79018e",
   "metadata": {},
   "source": [
    "### ðŸ§ª Try it out!\n",
    "\n",
    "Now that you've created a **sequential orchestration**, go ahead and run it! ðŸ”„  \n",
    "Youâ€™ll observe each agent executing in turn, passing its output to the nextâ€”perfect for linear workflows.\n",
    "\n",
    "\n",
    "### ðŸ§© Challenge\n",
    "\n",
    "- Try other orchestration patterns available in SK:\n",
    "  - **Concurrent** â€“ broadcast a task to all agents and collect responses in parallel.\n",
    "  - **Handoff** â€“ dynamically transfer control based on context or conditions.\n",
    "  - **Group Chat** â€“ multiple agents participate in a shared conversation under coordination.\n",
    "- Add **human-in-the-loop** support: insert `human_response_function` to pause and await user feedback between steps. :contentReference[oaicite:1]{index=1}  \n",
    "- **Food for thought:** Could you mix sequential, handoff, and human-in-the-loop patterns to model complex realâ€‘world processes?\n",
    "\n",
    "All orchestration types share a unified interfaceâ€”so switching patterns is seamless and requires minimal code changes.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
