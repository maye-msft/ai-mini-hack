{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c6811a4",
   "metadata": {},
   "source": [
    "# ðŸ§ª Lab 2: Use an MCP Server as a Plugin in a Semantic Kernel Agent\n",
    "\n",
    "In this lab, you'll learn how to **extend a Semantic Kernel agent** by connecting it to an **external MCP server**. MCP (Model Context Protocol) allows agents to invoke external tools, services, or other agents as plugins.\n",
    "\n",
    "You'll specifically:\n",
    "- Connect to the **GitHub MCP server** as a tool via `MCPStdioPlugin`\n",
    "- Use this plugin inside a **Semantic Kernel agent**\n",
    "- Interact with the agent through a chat interface\n",
    "- See the agent automatically call functions on the GitHub MCP server to answer questions\n",
    "\n",
    "This lab showcases how Semantic Kernel can leverage **modular, tool-augmented AI workflows** by treating external MCP servers as powerful extensions to the agent's reasoning capabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949ed733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from openai import AsyncAzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from semantic_kernel.connectors.ai import FunctionChoiceBehavior\n",
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    AzureChatCompletion,\n",
    "    AzureChatPromptExecutionSettings,\n",
    ")\n",
    "from semantic_kernel.connectors.mcp import MCPStdioPlugin\n",
    "from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread\n",
    "\n",
    "# Setup\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7727f84",
   "metadata": {},
   "source": [
    "The code block below initializes and connects to a GitHub MCP (Model Context Protocol) plugin using the `MCPStdioPlugin` interface.\n",
    "\n",
    "- `MCPStdioPlugin` is used to run the plugin as a subprocess that communicates via standard input/output (stdio).\n",
    "- The plugin is a Docker container hosted at `ghcr.io/github/github-mcp-server`.\n",
    "- The container is run with the `--rm` and `-i` flags:\n",
    "  - `--rm`: Automatically remove the container when it exits.\n",
    "  - `-i`: Keep STDIN open to allow interactive communication with the plugin.\n",
    "- An environment variable `GITHUB_PERSONAL_ACCESS_TOKEN` is passed into the container, which is retrieved from the local environment using `os.getenv(...)`.\n",
    "\n",
    "Finally, `await github_plugin.connect()` establishes the connection so that the plugin can be used as part of an MCP-enabled agent workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca2a8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "github_plugin = MCPStdioPlugin(\n",
    "    name=\"Github\",\n",
    "    description=\"Github Plugin\",\n",
    "    command=\"docker\",\n",
    "    args=[\n",
    "        \"run\",\n",
    "        \"-i\",\n",
    "        \"--rm\",\n",
    "        \"-e\",\n",
    "        \"GITHUB_PERSONAL_ACCESS_TOKEN\",\n",
    "        \"ghcr.io/github/github-mcp-server\",\n",
    "    ],\n",
    "    env={\"GITHUB_PERSONAL_ACCESS_TOKEN\": os.getenv(\"GITHUB_PERSONAL_ACCESS_TOKEN\")},\n",
    ")\n",
    "\n",
    "# Start the connection to the MCP plugin\n",
    "await github_plugin.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c9c81b",
   "metadata": {},
   "source": [
    "Now, let's set up an AI agent that can interact with an external MCP server as a plugin.\n",
    "\n",
    "Weâ€™ll first configure the Azure OpenAI chat completion service, then define an agent by giving it a name, description, and a clear set of instructions. \n",
    "\n",
    "Finally, we attach the MCP-based GitHub plugin so the agent can call functions exposed by the plugin to fulfill user requests dynamically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d59fff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the chat completion service\n",
    "service_id = \"azure_openai_chat\"\n",
    "async_openai_client = AsyncAzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_version=os.getenv(\"MODEL_DEPLOYMENT_API_VERSION\"),\n",
    ")\n",
    "chat_service = AzureChatCompletion(\n",
    "    service_id=service_id,\n",
    "    async_client=async_openai_client,\n",
    "    deployment_name=os.getenv(\"MODEL_DEPLOYMENT_NAME\"),\n",
    ")\n",
    "settings = AzureChatPromptExecutionSettings(service_id=service_id)\n",
    "settings.function_choice_behavior = FunctionChoiceBehavior.Auto()\n",
    "\n",
    "# Create the agent with the chat service and plugin\n",
    "github_agent = ChatCompletionAgent(\n",
    "    service=chat_service,\n",
    "    name=\"GithubAgent\",\n",
    "    description=\"A chat bot that helps users interact with Github.\",\n",
    "    instructions=\"\"\"\n",
    "You are a chat bot. And you help users interact with Github.\n",
    "You are especially good at answering questions about the Microsoft semantic-kernel project.\n",
    "You can call functions to get the information you need.\n",
    "\"\"\",\n",
    "    plugins=[github_plugin],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6577477",
   "metadata": {},
   "source": [
    "Now let's try it out! ðŸŽ‰\n",
    "\n",
    "We're spinning up a simple chat loop where you can talk directly with the agent â€” powered by Azure OpenAI and enhanced with GitHub superpowers via the MCP plugin.\n",
    "\n",
    "Letâ€™s see this agent in action! ðŸ¤–ðŸ’¬\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aa4346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the thread\n",
    "thread: ChatHistoryAgentThread = ChatHistoryAgentThread()\n",
    "\n",
    "# Run the agent as a chat\n",
    "while True:\n",
    "    user_input = input(\"Enter your message:\")\n",
    "    print(f\"\\nYou: {user_input}\")\n",
    "\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        break\n",
    "\n",
    "    response = await github_agent.get_response(\n",
    "        messages=user_input,\n",
    "        thread=thread,\n",
    "    )\n",
    "\n",
    "    assistant_reply = str(response)\n",
    "    print(f\"Bot: {assistant_reply}\")\n",
    "\n",
    "await github_plugin.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71784718",
   "metadata": {},
   "source": [
    "### ðŸ§ª Try it out!\n",
    "\n",
    "In this lab, you used the GitHub MCP Server â€” but the real power comes from the flexibility of the `MCPStdioPlugin` in Semantic Kernel. This component allows you to connect to **any tool that implements the Model Context Protocol (MCP)**.\n",
    "\n",
    "You can easily swap in other MCP-compatible servers, or even chain multiple plugins together to create powerful tool-augmented agents.\n",
    "\n",
    "---\n",
    "\n",
    "ðŸ§° **Explore These MCP Plugin Servers:**\n",
    "\n",
    "- ðŸ”— [Official MCP Server Integrations (GitHub)](https://github.com/modelcontextprotocol/servers?tab=readme-ov-file#%EF%B8%8F-official-integrations)  \n",
    "  A growing list of plugins including GitHub, Weather, Jira, Open Interpreter, and more.\n",
    "\n",
    "- ðŸ“š [10 Must-Know MCP Servers for Developers (DevShorts)](https://www.devshorts.in/p/ten-must-know-mcp-servers-for-every?utm_source=chatgpt.com)  \n",
    "  A curated blog post with descriptions, commands, and usage tips.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
